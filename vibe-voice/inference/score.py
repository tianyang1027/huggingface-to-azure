import os
import torch
from transformers import (
    AutoModelForCausalLM,
    AutoProcessor,
    AutoTokenizer,
    AutoFeatureExtractor
)
import soundfile as sf
import json
import tempfile

# Global variables
model = None
processor = None
device = "cuda" if torch.cuda.is_available() else "cpu"

def init():
    global model, processor
    print(f"ğŸš€ Initializing model on device: {device}")

    model_path = os.path.join(os.getenv("AZUREML_MODEL_DIR"), "VibeVoice-1.5B")
    print(f"ğŸ“‚ Loading model from: {model_path}")

    try:
        # å…ˆå°è¯• AutoProcessor
        try:
            processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
            print("âœ… Loaded AutoProcessor")
        except Exception as e:
            print(f"âš ï¸ AutoProcessor failed: {e}")
            # fallbackï¼šå°è¯• tokenizer æˆ– feature extractor
            try:
                processor = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
                print("âœ… Loaded AutoTokenizer")
            except Exception:
                processor = AutoFeatureExtractor.from_pretrained(model_path, trust_remote_code=True)
                print("âœ… Loaded AutoFeatureExtractor")

        # åŠ è½½æ¨¡å‹
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            trust_remote_code=True  # å¿…é¡»æœ‰
        ).to(device)

        print("âœ… Model loaded successfully")
    except Exception as e:
        print(f"âŒ Failed to load model: {str(e)}")
        raise

def run(raw_data):
    global model, processor
    try:
        if isinstance(raw_data, str):
            data = json.loads(raw_data)
        else:
            data = raw_data

        text = data.get("text")
        if not text:
            return {"error": "No text provided"}

        speaker = data.get("speaker", "default")
        sample_rate = data.get("sample_rate", 16000)

        print(f"ğŸ¤ Generating speech for text='{text[:50]}...' speaker={speaker}, sample_rate={sample_rate}")

        # æ¨ç†
        inputs = processor(text=text, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = model.generate(**inputs)

        # è§£ç æˆéŸ³é¢‘ï¼ˆæ³¨æ„ï¼šæœ‰äº› TTS æ¨¡å‹ä¸æ˜¯ç”¨ batch_decodeï¼Œè€Œæ˜¯ model è¾“å‡ºç›´æ¥å°±æ˜¯ audio tensorï¼‰
        try:
            audio_values = processor.batch_decode(outputs, return_tensors="pt")[0].cpu().numpy()
        except Exception:
            # fallbackï¼šå¦‚æœæ¨¡å‹ç›´æ¥è¾“å‡º audio
            if isinstance(outputs, torch.Tensor):
                audio_values = outputs[0].cpu().numpy()
            else:
                raise ValueError("Model outputs could not be converted to audio.")

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_dir = tempfile.gettempdir()
        audio_path = os.path.abspath(os.path.join(temp_dir, "output.wav"))
        sf.write(audio_path, audio_values, samplerate=sample_rate)

        print(f"âœ… Audio saved to {audio_path}")

        return {
            "audio_path": audio_path,
            "message": "success"
        }

    except Exception as e:
        print(f"âŒ Error in run(): {str(e)}")
        return {"error": str(e)}
